{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a09c88",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f8e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "from metrics import AverageMeter\n",
    "from loss import batch_all_triplet_loss, batch_hard_triplet_loss\n",
    "from tqdm import tqdm\n",
    "from test import result\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a023afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_planes, out_planes,\n",
    "            kernel_size=kernel_size, stride=stride,\n",
    "            padding=padding, bias=False\n",
    "        ) \n",
    "        self.bn = nn.BatchNorm2d(\n",
    "            out_planes,\n",
    "            eps=0.001, \n",
    "            momentum=0.1, \n",
    "            affine=True\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ec8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block35(nn.Module):\n",
    "\n",
    "    def __init__(self, scale=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = scale\n",
    "\n",
    "        self.branch0 = BasicConv2d(256, 32, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(256, 32, kernel_size=1, stride=1),\n",
    "            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(256, 32, kernel_size=1, stride=1),\n",
    "            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2d = nn.Conv2d(96, 256, kernel_size=1, stride=1)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        out = self.conv2d(out)\n",
    "        out = out * self.scale + x\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46f5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block17(nn.Module):\n",
    "\n",
    "    def __init__(self, scale=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = scale\n",
    "\n",
    "        self.branch0 = BasicConv2d(896, 128, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(896, 128, kernel_size=1, stride=1),\n",
    "            BasicConv2d(128, 128, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(128, 128, kernel_size=(7,1), stride=1, padding=(3,0))\n",
    "        )\n",
    "\n",
    "        self.conv2d = nn.Conv2d(256, 896, kernel_size=1, stride=1)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        out = self.conv2d(out)\n",
    "        out = out * self.scale + x\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f17b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block8(nn.Module):\n",
    "\n",
    "    def __init__(self, scale=1.0, noReLU=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = scale\n",
    "        self.noReLU = noReLU\n",
    "\n",
    "        self.branch0 = BasicConv2d(1792, 192, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(1792, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 192, kernel_size=(1,3), stride=1, padding=(0,1)),\n",
    "            BasicConv2d(192, 192, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        )\n",
    "\n",
    "        self.conv2d = nn.Conv2d(384, 1792, kernel_size=1, stride=1)\n",
    "        if not self.noReLU:\n",
    "            self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        out = self.conv2d(out)\n",
    "        out = out * self.scale + x\n",
    "        if not self.noReLU:\n",
    "            out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e81d66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixed_6a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.branch0 = BasicConv2d(256, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(256, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 192, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(192, 256, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce589a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixed_7a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv2d(896, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 384, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(896, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 256, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(896, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(256, 256, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2f95d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionResnetV1(nn.Module):\n",
    "    def __init__(self, pretrained=None, classify=False, num_classes=None, dropout_prob=0.6, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set simple attributes\n",
    "        self.pretrained = pretrained\n",
    "        self.classify = classify\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if pretrained == 'vggface2':\n",
    "            tmp_classes = 8631\n",
    "        elif pretrained == 'casia-webface':\n",
    "            tmp_classes = 10575\n",
    "        elif pretrained is None and self.classify and self.num_classes is None:\n",
    "            raise Exception('Exception occured.')\n",
    "        self.conv2d_1a = BasicConv2d(3, 32, kernel_size=3, stride=2)\n",
    "        self.conv2d_2a = BasicConv2d(32, 32, kernel_size=3, stride=1)\n",
    "        self.conv2d_2b = BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool_3a = nn.MaxPool2d(3, stride=2)\n",
    "        self.conv2d_3b = BasicConv2d(64, 80, kernel_size=1, stride=1)\n",
    "        self.conv2d_4a = BasicConv2d(80, 192, kernel_size=3, stride=1)\n",
    "        self.conv2d_4b = BasicConv2d(192, 256, kernel_size=3, stride=2)\n",
    "        self.repeat_1 = nn.Sequential(\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "        )\n",
    "        self.mixed_6a = Mixed_6a()\n",
    "        self.repeat_2 = nn.Sequential(\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "        )\n",
    "        self.mixed_7a = Mixed_7a()\n",
    "        self.repeat_3 = nn.Sequential(\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "        )\n",
    "        self.block8 = Block8(noReLU=True)\n",
    "        self.avgpool_1a = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.last_linear = nn.Linear(1792, 512, bias=False)\n",
    "        self.last_bn = nn.BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.logits = nn.Linear(512, tmp_classes)\n",
    "            load_weights(self, pretrained)\n",
    "\n",
    "        if self.classify and self.num_classes is not None:\n",
    "            self.logits = nn.Linear(512, self.num_classes)\n",
    "\n",
    "        self.device = torch.device('cpu')\n",
    "        if device is not None:\n",
    "            self.device = device\n",
    "            self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1a(x)\n",
    "        x = self.conv2d_2a(x)\n",
    "        x = self.conv2d_2b(x)\n",
    "        x = self.maxpool_3a(x)\n",
    "        x = self.conv2d_3b(x)\n",
    "        x = self.conv2d_4a(x)\n",
    "        x = self.conv2d_4b(x)\n",
    "        x = self.repeat_1(x)\n",
    "        x = self.mixed_6a(x)\n",
    "        x = self.repeat_2(x)\n",
    "        x = self.mixed_7a(x)\n",
    "        x = self.repeat_3(x)\n",
    "        x = self.block8(x)\n",
    "        x = self.avgpool_1a(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.last_linear(x.view(x.shape[0], -1))\n",
    "        x = self.last_bn(x)\n",
    "        if self.classify:\n",
    "            x = self.logits(x)\n",
    "        else:\n",
    "            x = F.normalize(x, p=2, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04246b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(mdl, name):\n",
    "    if name == 'vggface2':\n",
    "        path = 'https://github.com/timesler/facenet-pytorch/releases/download/v2.2.9/20180402-114759-vggface2.pt'\n",
    "    elif name == 'casia-webface':\n",
    "        path = 'https://github.com/timesler/facenet-pytorch/releases/download/v2.2.9/20180408-102900-casia-webface.pt'\n",
    "    else:\n",
    "        raise ValueError('Pretrained models only exist for \"vggface2\" and \"casia-webface\"')\n",
    "\n",
    "    model_dir = os.path.join(get_torch_home(), 'checkpoints')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    cached_file = os.path.join(model_dir, os.path.basename(path))\n",
    "    if not os.path.exists(cached_file):\n",
    "        download_url_to_file(path, cached_file)\n",
    "\n",
    "    state_dict = torch.load(cached_file)\n",
    "    mdl.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bbfc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_home():\n",
    "    torch_home = os.path.expanduser(\n",
    "        os.getenv(\n",
    "            'TORCH_HOME',\n",
    "            os.path.join(os.getenv('XDG_CACHE_HOME', '~/.cache'), 'torch')\n",
    "        )\n",
    "    )\n",
    "    return torch_home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add63de6",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c7e32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig('../Result/test_new_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a68b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(model,dataloader, device):\n",
    "    dist = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for _, eval_data in enumerate(tqdm(dataloader)):\n",
    "            eval_image = eval_data['image'].to(device)\n",
    "            print(eval_image)\n",
    "            eval_out = model(eval_image)['embeddings']\n",
    "            eval_pair = eval_data['pair_image'].to(device)\n",
    "            eval_pait_out = model(eval_pair)['embeddings']\n",
    "            # print(eval_out)\n",
    "            # print(\"-\"*10)\n",
    "            # print(eval_pait_out)\n",
    "            distance = torch.norm(eval_out - eval_pait_out, dim=1)\n",
    "            dist.append(list(distance.cpu().numpy()))\n",
    "\n",
    "    new_dist = []\n",
    "    for i in range(len(dist)):\n",
    "        for j in range(len(dist[i])):\n",
    "            new_dist.append(dist[i][j])\n",
    "    dist = np.asarray(new_dist)\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0708c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalulate(model, eval_loader1, eval_loader2, device):\n",
    "    dist1 = result(model,eval_loader1, device)\n",
    "    dist2 = result(model,eval_loader2, device)\n",
    "\n",
    "    with open('test.npy', 'wb') as f:\n",
    "        np.save(f, dist1)\n",
    "        np.save(f, dist2)\n",
    "\n",
    "    same_hist = plt.hist(dist1, 100, range=[np.floor(np.min([dist1.min(), dist2.min()])),np.ceil(np.max([dist1.max(), dist2.max()]))], alpha=0.5, label='same')\n",
    "    diff_hist = plt.hist(dist2, 100, range=[np.floor(np.min([dist1.min(), dist2.min()])),np.ceil(np.max([dist1.max(), dist2.max()]))], alpha=0.5, label='diff')\n",
    "    difference = same_hist[0] - diff_hist[0]\n",
    "    difference[:same_hist[0].argmax()] = np.Inf\n",
    "    difference[diff_hist[0].argmax():] = np.Inf\n",
    "    return (same_hist[1][np.where(difference <= 0)[0].min()] + same_hist[1][np.where(difference <= 0)[0].min() - 1])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03a16531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, dist_threshold, device):\n",
    "    label = []\n",
    "    pred = []\n",
    "    print(model)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for _, test_data in enumerate(tqdm(test_loader)):\n",
    "            test_image = test_data['image'].to(device)\n",
    "            test_target = test_data['target']\n",
    "            test_out = model(test_image)\n",
    "            test_pair = test_data['pair_image'].to(device)\n",
    "            test_pair_target = test_data['pair_target']\n",
    "            test_pait_out = model(test_pair)\n",
    "            distance = torch.norm(test_out['embeddings'] - test_pait_out['embeddings'], dim=1)\n",
    "            label.append(list((test_target == test_pair_target).cpu().numpy()))\n",
    "            pred.append(list((distance <= dist_threshold).cpu().numpy()))\n",
    "\n",
    "    new_label = []\n",
    "    new_pred = []\n",
    "    for i in range(len(label)):\n",
    "        for j in range(len(label[i])):\n",
    "            new_label.append(label[i][j])\n",
    "            new_pred.append(pred[i][j])\n",
    "\n",
    "\n",
    "    new_pred = [0 if i == False else 1 for i in new_pred]\n",
    "    new_label = [0 if i == False else 1 for i in new_label]\n",
    "    new_pred = np.array(new_pred)\n",
    "    new_label = np.array(new_label)\n",
    "    num_true = np.sum(new_pred==new_label)\n",
    "    acc = num_true/len(new_label)\n",
    "    print('Accuracy is:', acc)\n",
    "    print(classification_report(new_label, new_pred))\n",
    "    cm = confusion_matrix(new_label, new_pred)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plot_confusion_matrix(cm, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ede3a",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00e4c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(save_path, model, optimizer=None, scheduler=None):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    checkpoint = {\n",
    "        'model': model,\n",
    "        'optimizer': optimizer,\n",
    "        'scheduler': scheduler,\n",
    "    }\n",
    "    save_path = '../Model/' + save_path\n",
    "    torch.save(checkpoint, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1953a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(name, model, optimizer):\n",
    "    checkpoint = torch.load('../Model/' + name)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faeb0277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,valid_loader,valid_loader1,valid_loader2,optimizer,scheduler,num_epochs,eval_every,margin,device,name):\n",
    "    epoch_loss_list = {'train':[], 'valid':[]}\n",
    "    IOU_list = []\n",
    "    global_step = 0\n",
    "    train_loss = AverageMeter()\n",
    "    valid_loss = AverageMeter()\n",
    "    best_IOU = 1\n",
    "    total_step = len(train_loader)*num_epochs\n",
    "    count = 0\n",
    "    print(f'total steps: {total_step}')\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'epoch {epoch+1}')\n",
    "        #losses = []\n",
    "        for _, data in enumerate(tqdm(train_loader)):\n",
    "            if count > 0:\n",
    "                break\n",
    "            count += 1\n",
    "            model.train()\n",
    "            inputs = data['image'].to(device) # inputs\n",
    "            target = data['target'].to(device) # targets\n",
    "            embeddings = model(inputs)\n",
    "            loss, _ = batch_all_triplet_loss(target, embeddings, margin=margin, epoch=epoch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.update(loss.item())\n",
    "            global_step += 1\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "            ### print\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                for _, data in enumerate(tqdm(valid_loader)):\n",
    "                    inputs = data['image'].to(device) # inputs\n",
    "                    target = data['target'].to(device) # targets\n",
    "                    embeddings = model(inputs)\n",
    "                    loss, _ = batch_all_triplet_loss(target, embeddings, margin=margin, epoch=epoch)\n",
    "                    valid_loss.update(loss.item())\n",
    "\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}, lr: {:.4f}'\n",
    "                          .format(epoch+1, num_epochs, global_step, total_step, train_loss.avg, valid_loss.avg ,current_lr))\n",
    "\n",
    "        # valid\n",
    "        dist1 = result(model,valid_loader1,device)\n",
    "        dist2 = result(model,valid_loader2,device)\n",
    "        same_hist = plt.hist(dist1, 100, range=[np.floor(np.min([dist1.min(), dist2.min()])),np.ceil(np.max([dist1.max(), dist2.max()]))], alpha=0.5, label='same')\n",
    "        diff_hist = plt.hist(dist2, 100, range=[np.floor(np.min([dist1.min(), dist2.min()])),np.ceil(np.max([dist1.max(), dist2.max()]))], alpha=0.5, label='diff')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.savefig('../Result/distribution_epoch'+str(epoch+1)+'.png')\n",
    "        difference = same_hist[0] - diff_hist[0]\n",
    "        difference[:same_hist[0].argmax()] = np.Inf\n",
    "        difference[diff_hist[0].argmax():] = np.Inf\n",
    "        dist_threshold = (same_hist[1][np.where(difference <= 0)[0].min()] + same_hist[1][np.where(difference <= 0)[0].min() - 1])/2\n",
    "        overlap = np.sum(dist1>=dist_threshold) + np.sum(dist2<=dist_threshold)\n",
    "        IOU = overlap / (dist1.shape[0] * 2 - overlap)\n",
    "        print('dist_threshold:',dist_threshold,'overlap:',overlap,'IOU:',IOU)\n",
    "        plt.clf()\n",
    "\n",
    "        epoch_loss_list['train'].append(train_loss.avg)\n",
    "        epoch_loss_list['valid'].append(valid_loss.avg)\n",
    "        IOU_list.append(IOU)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,9))\n",
    "        ax1.plot(range(len(epoch_loss_list['train'])), epoch_loss_list['train'], label=('train_loss'))\n",
    "        ax1.plot(range(len(epoch_loss_list['valid'])), epoch_loss_list['valid'], label=('valid_loss'))\n",
    "        ax2.plot(range(len(IOU_list)), IOU_list, label=('IOU'))\n",
    "        ax1.legend(prop={'size': 15})\n",
    "        ax2.legend(prop={'size': 15})\n",
    "        plt.savefig('../Result/loss.png')\n",
    "        plt.clf()\n",
    "\n",
    "        if IOU < best_IOU:\n",
    "            best_IOU = IOU\n",
    "            save(name, model, optimizer, scheduler)\n",
    "\n",
    "        train_loss.reset()\n",
    "        valid_loss.reset()\n",
    "        scheduler.step()\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050f2ab",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9ee9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from sampler import PKSampler, PKSampler2\n",
    "\n",
    "def get_Sampler(sampler,dataset,p=15,k=20):\n",
    "    if sampler == 'all':\n",
    "        return PKSampler2(dataset, p=p, k=k)\n",
    "    else:\n",
    "        return PKSampler(dataset, p=p, k=k)\n",
    "\n",
    "def get_Optimizer(model, optimizer_type=None, lr=1e-3, weight_decay=1e-3):\n",
    "    if(optimizer_type=='sgd'):\n",
    "        return optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=weight_decay)\n",
    "    elif(optimizer_type=='rmsprop'):\n",
    "        return optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif(optimizer_type=='adadelta'):\n",
    "        return optim.Adadelta(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        return optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def get_Scheduler(optimizer, lr, scheduler_name=None):\n",
    "    if(scheduler_name=='cyclic'):\n",
    "        return optim.lr_scheduler.CyclicLR(optimizer, base_lr=5e-4, max_lr=lr, step_size_up=500)\n",
    "    elif(scheduler_name=='cosine'):\n",
    "        return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=1000)\n",
    "    elif(scheduler_name=='multistep'):\n",
    "        # return optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3,13,30], gamma=0.3)\n",
    "        return optim.lr_scheduler.MultiStepLR(optimizer, milestones=[6,20,40], gamma=0.1)\n",
    "    else:\n",
    "        return optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ffcb5",
   "metadata": {},
   "source": [
    "## Sampler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa16b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import Sampler\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def samples(df):\n",
    "    label_to_samples = []\n",
    "    samples = []\n",
    "    label = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if index == 0:\n",
    "            samples.append(index)\n",
    "            label = row['target']\n",
    "        else:\n",
    "            if row['target'] != label:\n",
    "                label_to_samples.append(samples)\n",
    "                samples = []\n",
    "                label = row['target']\n",
    "            samples.append(index)\n",
    "    return label_to_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bdc02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PKSampler(Sampler):\n",
    "\n",
    "    def __init__(self, data_source, p=15, k=20):\n",
    "        super().__init__(data_source)\n",
    "        self.p = p\n",
    "        self.k = k\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        pk_count = len(self) // (self.p * self.k)\n",
    "        for _ in range(pk_count):\n",
    "            labels = np.random.choice(np.arange(len(self.data_source.label_to_samples)), self.p, replace=False)\n",
    "            for l in labels:\n",
    "                indices = self.data_source.label_to_samples[l]\n",
    "                replace = True if len(indices) < self.k else False\n",
    "                for i in np.random.choice(indices, self.k, replace=replace):\n",
    "                    yield i\n",
    "\n",
    "    def __len__(self):\n",
    "        pk = self.p * self.k\n",
    "        samples = ((len(self.data_source) - 1) // pk + 1) * pk\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25c21ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(iterable, n):\n",
    "    it = itertools.cycle(iter(iterable))\n",
    "    for _ in range((len(iterable) - 1) // n + 1):\n",
    "        yield list(itertools.islice(it, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f3e6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PKSampler2(Sampler):\n",
    "\n",
    "    def __init__(self, data_source, p=15, k=20):\n",
    "        super().__init__(data_source)\n",
    "        self.p = p\n",
    "        self.k = k\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        rand_labels = np.random.permutation(np.arange(len(self.data_source.label_to_samples)))\n",
    "        for labels in grouper(rand_labels, self.p):\n",
    "            for l in labels:\n",
    "                indices = self.data_source.label_to_samples[l]\n",
    "                replace = True if len(indices) < self.k else False\n",
    "                for j in np.random.choice(indices, self.k, replace=replace):\n",
    "                    yield j\n",
    "\n",
    "    def __len__(self):\n",
    "        num_labels = len(self.data_source.label_to_samples)\n",
    "        samples = ((num_labels - 1) // self.p + 1) * self.p * self.k\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a7b93",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f946a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7cd06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionResnet(nn.Module):\n",
    "    def __init__(self, device, pool=None, dropout=0.3, pretrain=True):\n",
    "        super(InceptionResnet, self).__init__()\n",
    "        if pretrain:\n",
    "            self.net = InceptionResnetV1(pretrained='vggface2', dropout_prob=dropout, device=device)\n",
    "        else:\n",
    "            self.net = InceptionResnetV1(dropout_prob=dropout, device=device)\n",
    "        self.out_features = self.net.last_linear.in_features\n",
    "        if pool == 'gem':\n",
    "            self.net.avgpool_1a = GeM(p_trainable=True)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class EfficientNetEncoderHead(nn.Module):\n",
    "    def __init__(self, depth, pretrain=True):\n",
    "        super(EfficientNetEncoderHead, self).__init__()\n",
    "        self.depth = depth\n",
    "        if pretrain:\n",
    "            self.net = EfficientNet.from_pretrained(f'efficientnet-b{self.depth}')\n",
    "        else:\n",
    "            self.net = EfficientNet.from_name(f'efficientnet-b{self.depth}')\n",
    "        self.out_features = self.net._fc.in_features\n",
    "    def forward(self, x):\n",
    "        return self.net.extract_features(x)\n",
    "\n",
    "class SEResNeXt101(nn.Module):\n",
    "    def __init__(self, pretrain=True):\n",
    "        super(SEResNeXt101, self).__init__()\n",
    "        self.net = timm.create_model('gluon_seresnext101_32x4d', pretrained=pretrain)\n",
    "        # the output size of this model\n",
    "        self.out_features = self.net.fc.in_features\n",
    "    def forward(self, x):\n",
    "        return self.net.forward_features(x)\n",
    "\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, p_trainable=True):\n",
    "        super(GeM,self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = Parameter(torch.ones(1)*p)\n",
    "        else:\n",
    "            self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "class FaceNet(nn.Module):\n",
    "    def __init__(self, model_name=None, pool=None, dropout=0.0, pretrain=True, embedding_size=512, device=None):\n",
    "        super(FaceNet, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        if(model_name=='resnet'):\n",
    "            self.model = SEResNeXt101(pretrain)\n",
    "        elif(model_name=='effnet'):\n",
    "            self.model = EfficientNetEncoderHead(depth=5, pretrain=pretrain)\n",
    "        else:\n",
    "            self.model = InceptionResnet(device, pool=pool, dropout=dropout, pretrain=pretrain)    \n",
    "        if(pool == \"gem\"):    \n",
    "            self.global_pool = GeM(p_trainable=True)\n",
    "        else:\n",
    "            self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.neck = nn.Sequential(\n",
    "                nn.Linear(self.model.out_features, embedding_size, bias=True),\n",
    "                nn.BatchNorm1d(embedding_size, eps=0.001),\n",
    "            )\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        if self.model_name == None:\n",
    "            return self.model(x)\n",
    "        x = self.model(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x[:,:,0,0]\n",
    "        embeddings = self.neck(x)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b548e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, features):\n",
    "        cosine = F.linear(F.normalize(features), F.normalize(self.weight))\n",
    "        return cosine\n",
    "\n",
    "class FaceNet2(nn.Module):\n",
    "    def __init__(self, num_classes, model_name=None, pool=None, dropout=0.0, embedding_size=512, device='cuda', pretrain=True):\n",
    "        super(FaceNet2, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "  \n",
    "        if(model_name=='resnet'):\n",
    "            self.model = SEResNeXt101(pretrain)\n",
    "        elif(model_name=='effnet'):\n",
    "            self.model = EfficientNetEncoderHead(depth=3, pretrain=pretrain)\n",
    "        else:\n",
    "            self.model = InceptionResnet(device, pool=pool, dropout=dropout, pretrain=pretrain)\n",
    "        if(pool == \"gem\"):\n",
    "            self.global_pool = GeM(p_trainable=True)\n",
    "        else:\n",
    "            self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.neck = nn.Sequential(\n",
    "                nn.Linear(self.model.out_features, embedding_size, bias=True),\n",
    "                nn.BatchNorm1d(embedding_size, eps=0.001),\n",
    "            )\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.head = ArcMarginProduct(embedding_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.model_name == None:\n",
    "            embeddings = self.model(x)\n",
    "            logits = self.head(embeddings)\n",
    "            return {'logits': logits, 'embeddings': embeddings}\n",
    "        x = self.model(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x[:,:,0,0]\n",
    "        embeddings = self.neck(x)\n",
    "        logits = self.head(embeddings)\n",
    "        return {'logits': logits, 'embeddings': embeddings}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0706566",
   "metadata": {},
   "source": [
    "## Metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbad42f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self) -> None:\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.val = 0.0\n",
    "        self.avg = 0.0\n",
    "        self.sum = 0.0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val: float, n: int = 1) -> None:\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f950c",
   "metadata": {},
   "source": [
    "## Loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e919058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def _pairwise_distances(embeddings, squared=False):\n",
    "    dot_product = torch.matmul(embeddings, embeddings.t())\n",
    "    square_norm = torch.diag(dot_product)\n",
    "    distances = square_norm.unsqueeze(0) - 2.0 * dot_product + square_norm.unsqueeze(1)\n",
    "    distances[distances < 0] = 0\n",
    "\n",
    "    if not squared:\n",
    "        mask = distances.eq(0).float()\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = (1.0 -mask) * torch.sqrt(distances)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def _get_triplet_mask(labels):\n",
    "    indices_equal = torch.eye(labels.size(0)).bool()\n",
    "    indices_not_equal = ~indices_equal\n",
    "    i_not_equal_j = indices_not_equal.unsqueeze(2)\n",
    "    i_not_equal_k = indices_not_equal.unsqueeze(1)\n",
    "    j_not_equal_k = indices_not_equal.unsqueeze(0)\n",
    "\n",
    "    distinct_indices = (i_not_equal_j & i_not_equal_k) & j_not_equal_k\n",
    "\n",
    "\n",
    "    label_equal = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "    i_equal_j = label_equal.unsqueeze(2)\n",
    "    i_equal_k = label_equal.unsqueeze(1)\n",
    "\n",
    "    valid_labels = ~i_equal_k & i_equal_j\n",
    "\n",
    "    return valid_labels & distinct_indices.cuda()\n",
    "\n",
    "\n",
    "def _get_anchor_positive_triplet_mask(labels, device):\n",
    "    indices_equal = torch.eye(labels.size(0)).bool().to(device)\n",
    "    indices_not_equal = ~indices_equal\n",
    "    labels_equal = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "\n",
    "    return labels_equal.to(device) & indices_not_equal.to(device)\n",
    "\n",
    "\n",
    "def _get_anchor_negative_triplet_mask(labels):\n",
    "\n",
    "    return ~(labels.unsqueeze(0) == labels.unsqueeze(1))\n",
    "\n",
    "\n",
    "def batch_hard_triplet_loss(labels, embeddings, margin, squared=False, device='cpu'):\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels, device).float()\n",
    "    anchor_positive_dist = mask_anchor_positive.to(device) * pairwise_dist.to(device)\n",
    "    hardest_positive_dist, _ = anchor_positive_dist.max(1, keepdim=True)\n",
    "    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels).float()\n",
    "    max_anchor_negative_dist, _ = pairwise_dist.max(1, keepdim=True)\n",
    "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "    hardest_negative_dist, _ = anchor_negative_dist.min(1, keepdim=True)\n",
    "    tl = hardest_positive_dist.to(device) - hardest_negative_dist.to(device) + margin\n",
    "    tl[tl < 0] = 0\n",
    "    triplet_loss = tl.mean()\n",
    "\n",
    "    return triplet_loss\n",
    "\n",
    "def batch_all_triplet_loss(labels, embeddings, margin, squared=False, epoch=0):\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    anchor_positive_dist = pairwise_dist.unsqueeze(2)\n",
    "    anchor_negative_dist = pairwise_dist.unsqueeze(1)\n",
    "    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n",
    "    mask = _get_triplet_mask(labels)\n",
    "    triplet_loss = mask.float() * triplet_loss\n",
    "    triplet_loss[triplet_loss < margin] = 0\n",
    "    valid_triplets = triplet_loss[triplet_loss > 1e-16]\n",
    "    num_positive_triplets = valid_triplets.size(0)\n",
    "    num_valid_triplets = mask.sum()\n",
    "\n",
    "    fraction_positive_triplets = num_positive_triplets / (num_valid_triplets.float() + 1e-16)\n",
    "    triplet_loss = triplet_loss.sum() / (num_positive_triplets + 1e-16)\n",
    "    return triplet_loss, fraction_positive_triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d25f5c",
   "metadata": {},
   "source": [
    "## Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d1662c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, mode: str, label_to_samples=None):\n",
    "        self.df = dataframe\n",
    "        self.mode = mode\n",
    "        transforms_list1 = [transforms.Resize((128,128)),\n",
    "                          transforms.RandomHorizontalFlip(p=0.5),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                std=[0.229, 0.224, 0.225])]\n",
    "        transforms_list2 = [transforms.Resize((128,128)),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                std=[0.229, 0.224, 0.225])]\n",
    "        self.transforms_train = transforms.Compose(transforms_list1)\n",
    "        self.transforms_test = transforms.Compose(transforms_list2)\n",
    "        self.label_to_samples = label_to_samples\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        target = self.df.iloc[index]['target']\n",
    "        image_path = self.df.iloc[index]['path']\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        if self.mode=='train' or self.mode=='valid':\n",
    "            img = self.transforms_train(img)\n",
    "            return {'image':img, 'target':target}\n",
    "        else:\n",
    "            img = self.transforms_test(img)\n",
    "            pair_path = self.df.iloc[index]['pair_path']\n",
    "            pair_target = self.df.iloc[index]['pair_target']\n",
    "            pair_img = Image.open(pair_path)\n",
    "            pair_img = self.transforms_test(pair_img)\n",
    "            return {'image':img, 'target':target, 'pair_image':pair_img, 'pair_target':pair_target}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e6661",
   "metadata": {},
   "source": [
    "## main_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78d57f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 456/456 [48:38<00:00,  6.40s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 456/456 [47:08<00:00,  6.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0499999523162842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [05:16<00:00,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9577290959580377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3241\n",
      "           1       0.99      0.93      0.96      3241\n",
      "\n",
      "    accuracy                           0.96      6482\n",
      "   macro avg       0.96      0.96      0.96      6482\n",
      "weighted avg       0.96      0.96      0.96      6482\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[3197   44]\n",
      " [ 230 3011]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset import TripletDataset\n",
    "from model import FaceNet\n",
    "from sampler import samples\n",
    "from train import train, load, save\n",
    "from test import evalulate, test\n",
    "from util import get_Optimizer, get_Scheduler, get_Sampler\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    " \n",
    "    BATCH_SIZE=128\n",
    "    NUM_WORKERS = 2\n",
    "    embedding_size = 512\n",
    "  \n",
    "    sampler = None\n",
    "    weight_decay = 1e-3\n",
    "    lr = 3e-6\n",
    "    dropout = 0.3\n",
    "    \n",
    "    model_name = None\n",
    "    pretrain = True\n",
    "    \n",
    "    pool= None\n",
    "    \n",
    "    scheduler_name = 'multistep'\n",
    "    \n",
    "    optimizer_type = None\n",
    "    num_epochs = 20\n",
    "    eval_every = 1000\n",
    "   \n",
    "    margin=2\n",
    "   \n",
    "    name = 'arcface1.pt'\n",
    "    load_local_model = False\n",
    "\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Device:\",device)\n",
    "\n",
    "    df_eval1 = pd.read_csv('../Datasets/eval_same.csv')\n",
    "    df_eval2 = pd.read_csv('../Datasets/eval_diff.csv')\n",
    "    df_test = pd.read_csv('../Datasets/test.csv')\n",
    "\n",
    "    eval_dataset1 = TripletDataset(df_eval1, mode='eval')\n",
    "    eval_dataset2 = TripletDataset(df_eval2, mode='eval')\n",
    "    test_dataset = TripletDataset(df_test, mode='test')\n",
    "\n",
    "    eval_loader1 = DataLoader(eval_dataset1, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, drop_last=False)\n",
    "    eval_loader2 = DataLoader(eval_dataset2, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, drop_last=False)\n",
    "    facenet = torch.load('../models/InceptionResNetV1_ArcFace.pt')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "    dist_threshold = evalulate(facenet, eval_loader1, eval_loader2, device)\n",
    "    print(dist_threshold)\n",
    "    test(facenet,test_loader,dist_threshold,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2c7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
